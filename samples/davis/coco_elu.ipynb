{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"coco_elu.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"HUplDBbTZw_N","colab_type":"code","outputId":"256efa15-d73f-48cf-97da-0e959babaf9b","executionInfo":{"status":"ok","timestamp":1548258118211,"user_tz":0,"elapsed":9976,"user":{"displayName":"Jayadeep Sasikumar","photoUrl":"","userId":"11146727263730048505"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"],"name":"stdout"}]},{"metadata":{"id":"He5lQQpLYe-m","colab_type":"code","colab":{}},"cell_type":"code","source":["def restart_kernel():\n","  \"\"\"\n","  Restart the kernel. This will clear off the variables as\n","  well as the entire workspace. Any downloaded files or cloned repos\n","  will be cleared off. Think of this as a hard reset.\n","  \"\"\"\n","  os.system('kill -9 -1')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LuTXSPtQZz2c","colab_type":"code","colab":{}},"cell_type":"code","source":["def check_available_memory():\n","  \"\"\"\n","  Prints a summary of both the general and GPU RAM status.\n","  \"\"\"\n","  GPUs = GPU.getGPUs()\n","  # XXX: only one GPU on Colab and isnâ€™t guaranteed\n","  gpu = GPUs[0]\n","  def printm():\n","   process = psutil.Process(os.getpid())\n","   print(\"Gen RAM Free: \" + \\\n","         humanize.naturalsize( psutil.virtual_memory().available ),\n","         \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","   print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | \"\\\n","         \"Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed,\n","                                  gpu.memoryUtil*100, gpu.memoryTotal))\n","  printm()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EOi5xLkHXu9g","colab_type":"text"},"cell_type":"markdown","source":["## Cloning into (or taking a pull of) the Mask R-CNN fork"]},{"metadata":{"id":"dlYpyOS1b1y4","colab_type":"code","colab":{}},"cell_type":"code","source":["def refresh_repo():\n","  \"\"\"\n","  Refreshes the local repo. If the repo is not present, clones the Mask R-CNN\n","  fork, if it's present, takes a pull from the origin.\n","  \"\"\"\n","  items = os.listdir()\n","  if items == ['.config', 'sample_data']:\n","    os.system('git clone https://github.com/JayadeepSasikumar/Mask_RCNN.git')\n","  else:\n","    if items == ['.config', 'Mask_RCNN', 'sample_data']:\n","      os.system('cd Mask_RCNN')\n","    os.system('git pull origin master')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dCGMsXLDucC7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"943ba6dc-7bf6-4a4c-acb7-0c882b69d172","executionInfo":{"status":"ok","timestamp":1548266335068,"user_tz":0,"elapsed":2096,"user":{"displayName":"Jayadeep Sasikumar","photoUrl":"","userId":"11146727263730048505"}}},"cell_type":"code","source":["refresh_repo()"],"execution_count":73,"outputs":[{"output_type":"stream","text":["events.out.tfevents.1548260164.2fdbe572467e  mask_rcnn_coco_0001.h5\n","events.out.tfevents.1548260446.2fdbe572467e  mask_rcnn_coco_0002.h5\n"],"name":"stdout"}]},{"metadata":{"id":"cAsFP_k4y2fE","colab_type":"text"},"cell_type":"markdown","source":["The experiments were conducted inside the davis folder inside samples. Changing directory to Mask_RCNN/samples/davis"]},{"metadata":{"id":"vmfi7sVGerSJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2e71e152-8218-46fd-87a7-e823f0c29172","executionInfo":{"status":"ok","timestamp":1548265134712,"user_tz":0,"elapsed":469,"user":{"displayName":"Jayadeep Sasikumar","photoUrl":"","userId":"11146727263730048505"}}},"cell_type":"code","source":["cd /content/Mask_RCNN/samples/davis"],"execution_count":67,"outputs":[{"output_type":"stream","text":["/content/Mask_RCNN/samples/davis\n"],"name":"stdout"}]},{"metadata":{"id":"cZcqJRIgzOf2","colab_type":"text"},"cell_type":"markdown","source":["## 1. Loading the required imports and setting the constants"]},{"metadata":{"id":"SXAM6iQpupLK","colab_type":"code","outputId":"5910e824-0990-424e-a3d8-88a32312ebd3","executionInfo":{"status":"ok","timestamp":1548258143701,"user_tz":0,"elapsed":1629,"user":{"displayName":"Jayadeep Sasikumar","photoUrl":"","userId":"11146727263730048505"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import cv2\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"../../\")\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn.config import Config\n","from mrcnn import utils\n","import mrcnn.elu_model as modellib\n","from mrcnn import visualize\n","from mrcnn.model import log\n","\n","%matplotlib inline \n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","DATA_DIR = os.path.join(ROOT_DIR, \"davis_data\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"Ipmx6S1rur0_","colab_type":"code","colab":{}},"cell_type":"code","source":["class CocoConfig(Config):\n","    \"\"\"Configuration for training on MS COCO.\n","    Derives from the base Config class and overrides values specific\n","    to the COCO dataset.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"coco\"\n","\n","    # We use a GPU with 12GB memory, when fine-tuning the whole network,\n","    # ~10GB is required for 1 image.\n","    IMAGES_PER_GPU = 1\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 80  # COCO has 80 classes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_wbCdfSKu0t5","colab_type":"code","colab":{}},"cell_type":"code","source":["DEFAULT_DATASET_YEAR = '2014'\n","\n","class CocoDataset(utils.Dataset):\n","    def load_coco(self, dataset_dir, subset, year=DEFAULT_DATASET_YEAR, class_ids=None,\n","                  class_map=None, return_coco=False, auto_download=False):\n","        \"\"\"Load a subset of the COCO dataset.\n","        dataset_dir: The root directory of the COCO dataset.\n","        subset: What to load (train, val, minival, valminusminival)\n","        year: What dataset year to load (2014, 2017) as a string, not an integer\n","        class_ids: If provided, only loads images that have the given classes.\n","        class_map: TODO: Not implemented yet. Supports maping classes from\n","            different datasets to the same class ID.\n","        return_coco: If True, returns the COCO object.\n","        auto_download: Automatically download and unzip MS-COCO images and annotations\n","        \"\"\"\n","\n","        if auto_download is True:\n","            self.auto_download(dataset_dir, subset, year)\n","\n","        coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, subset, year))\n","        if subset == \"minival\" or subset == \"valminusminival\":\n","            subset = \"val\"\n","        image_dir = \"{}/{}{}\".format(dataset_dir, subset, year)\n","\n","        # Load all classes or a subset?\n","        if not class_ids:\n","            # All classes\n","            class_ids = sorted(coco.getCatIds())\n","\n","        # All images or a subset?\n","        if class_ids:\n","            image_ids = []\n","            for id in class_ids:\n","                image_ids.extend(list(coco.getImgIds(catIds=[id])))\n","            # Remove duplicates\n","            image_ids = list(set(image_ids))\n","        else:\n","            # All images\n","            image_ids = list(coco.imgs.keys())\n","\n","        # Add classes\n","        for i in class_ids:\n","            self.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])\n","\n","        # Add images\n","        for i in image_ids:\n","            self.add_image(\n","                \"coco\", image_id=i,\n","                path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n","                width=coco.imgs[i][\"width\"],\n","                height=coco.imgs[i][\"height\"],\n","                annotations=coco.loadAnns(coco.getAnnIds(\n","                    imgIds=[i], catIds=class_ids, iscrowd=None)))\n","        if return_coco:\n","            return coco\n","\n","    def auto_download(self, dataDir, dataType, dataYear):\n","        \"\"\"Download the COCO dataset/annotations if requested.\n","        dataDir: The root directory of the COCO dataset.\n","        dataType: What to load (train, val, minival, valminusminival)\n","        dataYear: What dataset year to load (2014, 2017) as a string, not an integer\n","        Note:\n","            For 2014, use \"train\", \"val\", \"minival\", or \"valminusminival\"\n","            For 2017, only \"train\" and \"val\" annotations are available\n","        \"\"\"\n","\n","        # Setup paths and file names\n","        if dataType == \"minival\" or dataType == \"valminusminival\":\n","            imgDir = \"{}/{}{}\".format(dataDir, \"val\", dataYear)\n","            imgZipFile = \"{}/{}{}.zip\".format(dataDir, \"val\", dataYear)\n","            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(\"val\", dataYear)\n","        else:\n","            imgDir = \"{}/{}{}\".format(dataDir, dataType, dataYear)\n","            imgZipFile = \"{}/{}{}.zip\".format(dataDir, dataType, dataYear)\n","            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(dataType, dataYear)\n","        # print(\"Image paths:\"); print(imgDir); print(imgZipFile); print(imgURL)\n","\n","        # Create main folder if it doesn't exist yet\n","        if not os.path.exists(dataDir):\n","            os.makedirs(dataDir)\n","\n","        # Download images if not available locally\n","        if not os.path.exists(imgDir):\n","            os.makedirs(imgDir)\n","            print(\"Downloading images to \" + imgZipFile + \" ...\")\n","            with urllib.request.urlopen(imgURL) as resp, open(imgZipFile, 'wb') as out:\n","                shutil.copyfileobj(resp, out)\n","            print(\"... done downloading.\")\n","            print(\"Unzipping \" + imgZipFile)\n","            with zipfile.ZipFile(imgZipFile, \"r\") as zip_ref:\n","                zip_ref.extractall(dataDir)\n","            print(\"... done unzipping\")\n","        print(\"Will use images in \" + imgDir)\n","\n","        # Setup annotations data paths\n","        annDir = \"{}/annotations\".format(dataDir)\n","        if dataType == \"minival\":\n","            annZipFile = \"{}/instances_minival2014.json.zip\".format(dataDir)\n","            annFile = \"{}/instances_minival2014.json\".format(annDir)\n","            annURL = \"https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0\"\n","            unZipDir = annDir\n","        elif dataType == \"valminusminival\":\n","            annZipFile = \"{}/instances_valminusminival2014.json.zip\".format(dataDir)\n","            annFile = \"{}/instances_valminusminival2014.json\".format(annDir)\n","            annURL = \"https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0\"\n","            unZipDir = annDir\n","        else:\n","            annZipFile = \"{}/annotations_trainval{}.zip\".format(dataDir, dataYear)\n","            annFile = \"{}/instances_{}{}.json\".format(annDir, dataType, dataYear)\n","            annURL = \"http://images.cocodataset.org/annotations/annotations_trainval{}.zip\".format(dataYear)\n","            unZipDir = dataDir\n","        # print(\"Annotations paths:\"); print(annDir); print(annFile); print(annZipFile); print(annURL)\n","\n","        # Download annotations if not available locally\n","        if not os.path.exists(annDir):\n","            os.makedirs(annDir)\n","        if not os.path.exists(annFile):\n","            if not os.path.exists(annZipFile):\n","                print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n","                with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n","                    shutil.copyfileobj(resp, out)\n","                print(\"... done downloading.\")\n","            print(\"Unzipping \" + annZipFile)\n","            with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n","                zip_ref.extractall(unZipDir)\n","            print(\"... done unzipping\")\n","        print(\"Will use annotations in \" + annFile)\n","\n","    def load_mask(self, image_id):\n","        \"\"\"Load instance masks for the given image.\n","\n","        Different datasets use different ways to store masks. This\n","        function converts the different mask format to one format\n","        in the form of a bitmap [height, width, instances].\n","\n","        Returns:\n","        masks: A bool array of shape [height, width, instance count] with\n","            one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        # If not a COCO image, delegate to parent class.\n","        image_info = self.image_info[image_id]\n","        if image_info[\"source\"] != \"coco\":\n","            return super(CocoDataset, self).load_mask(image_id)\n","\n","        instance_masks = []\n","        class_ids = []\n","        annotations = self.image_info[image_id][\"annotations\"]\n","        # Build mask of shape [height, width, instance_count] and list\n","        # of class IDs that correspond to each channel of the mask.\n","        for annotation in annotations:\n","            class_id = self.map_source_class_id(\n","                \"coco.{}\".format(annotation['category_id']))\n","            if class_id:\n","                m = self.annToMask(annotation, image_info[\"height\"],\n","                                   image_info[\"width\"])\n","                # Some objects are so small that they're less than 1 pixel area\n","                # and end up rounded out. Skip those objects.\n","                if m.max() < 1:\n","                    continue\n","                # Is it a crowd? If so, use a negative class ID.\n","                if annotation['iscrowd']:\n","                    # Use negative class ID for crowds\n","                    class_id *= -1\n","                    # For crowd masks, annToMask() sometimes returns a mask\n","                    # smaller than the given dimensions. If so, resize it.\n","                    if m.shape[0] != image_info[\"height\"] or m.shape[1] != image_info[\"width\"]:\n","                        m = np.ones([image_info[\"height\"], image_info[\"width\"]], dtype=bool)\n","                instance_masks.append(m)\n","                class_ids.append(class_id)\n","\n","        # Pack instance masks into an array\n","        if class_ids:\n","            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n","            class_ids = np.array(class_ids, dtype=np.int32)\n","            return mask, class_ids\n","        else:\n","            # Call super class to return an empty mask\n","            return super(CocoDataset, self).load_mask(image_id)\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return a link to the image in the COCO Website.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"coco\":\n","            return \"http://cocodataset.org/#explore?id={}\".format(info[\"id\"])\n","        else:\n","            super(CocoDataset, self).image_reference(image_id)\n","\n","    # The following two functions are from pycocotools with a few changes.\n","\n","    def annToRLE(self, ann, height, width):\n","        \"\"\"\n","        Convert annotation which can be polygons, uncompressed RLE to RLE.\n","        :return: binary mask (numpy 2D array)\n","        \"\"\"\n","        segm = ann['segmentation']\n","        if isinstance(segm, list):\n","            # polygon -- a single object might consist of multiple parts\n","            # we merge all parts into one mask rle code\n","            rles = maskUtils.frPyObjects(segm, height, width)\n","            rle = maskUtils.merge(rles)\n","        elif isinstance(segm['counts'], list):\n","            # uncompressed RLE\n","            rle = maskUtils.frPyObjects(segm, height, width)\n","        else:\n","            # rle\n","            rle = ann['segmentation']\n","        return rle\n","\n","    def annToMask(self, ann, height, width):\n","        \"\"\"\n","        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n","        :return: binary mask (numpy 2D array)\n","        \"\"\"\n","        rle = self.annToRLE(ann, height, width)\n","        m = maskUtils.decode(rle)\n","        return m"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v6nmIUm3NutO","colab_type":"code","colab":{}},"cell_type":"code","source":["config = CocoConfig()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2ZzZ171iN3cb","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create model in training mode\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                          model_dir=MODEL_DIR)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BL56nI67WkWn","colab_type":"code","colab":{}},"cell_type":"code","source":["from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","from pycocotools import mask as maskUtils"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qrsUnKqI0VMf","colab_type":"text"},"cell_type":"markdown","source":["## 2. Downloading the training and validation datasets."]},{"metadata":{"id":"CUQGlOd2YawM","colab_type":"code","colab":{}},"cell_type":"code","source":["import shutil\n","import urllib.request\n","import zipfile\n","\n","print(\"Downloading images to \" + imgZipFile + \" ...\")\n","with urllib.request.urlopen(imgURL) as resp, open(imgZipFile, 'wb') as out:\n","    shutil.copyfileobj(resp, out)\n","print(\"... done downloading.\")\n","print(\"Unzipping \" + imgZipFile)\n","with zipfile.ZipFile(imgZipFile, \"r\") as zip_ref:\n","    zip_ref.extractall(dataDir)\n","print(\"... done unzipping\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ik_SHKHBN_jd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"0694eccc-35ed-48cf-ca8e-cb1ba8fd8858","executionInfo":{"status":"ok","timestamp":1548259350394,"user_tz":0,"elapsed":249433,"user":{"displayName":"Jayadeep Sasikumar","photoUrl":"","userId":"11146727263730048505"}}},"cell_type":"code","source":["import shutil\n","import urllib.request\n","import zipfile\n","\n","# Training dataset\n","dataset_train = CocoDataset()\n","dataset_train.load_coco('coco_dataset', \"train\", year='2014', auto_download=True)\n","dataset_train.load_coco('coco_dataset', \"valminusminival\", year='2014', auto_download=True)\n","dataset_train.prepare()"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Will use images in coco_dataset/train2014\n","Will use annotations in coco_dataset/annotations/instances_train2014.json\n","loading annotations into memory...\n","Done (t=12.91s)\n","creating index...\n","index created!\n","Downloading images to coco_dataset/val2014.zip ...\n","... done downloading.\n","Unzipping coco_dataset/val2014.zip\n","... done unzipping\n","Will use images in coco_dataset/val2014\n","Downloading zipped annotations to coco_dataset/instances_valminusminival2014.json.zip ...\n","... done downloading.\n","Unzipping coco_dataset/instances_valminusminival2014.json.zip\n","... done unzipping\n","Will use annotations in coco_dataset/annotations/instances_valminusminival2014.json\n","loading annotations into memory...\n","Done (t=6.88s)\n","creating index...\n","index created!\n"],"name":"stdout"}]},{"metadata":{"id":"3D-4hQoswq4J","colab_type":"code","colab":{}},"cell_type":"code","source":["# Validation dataset\n","dataset_val = CocoDataset()\n","val_type = \"minival\"\n","dataset_val.load_coco('coco_dataset', val_type, year='2014', auto_download=True)\n","dataset_val.prepare()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xfRCMmzN0gmX","colab_type":"text"},"cell_type":"markdown","source":["## 3. Training the model on MS-COCO dataset\n","\n","Training is done in 3 stages, the number of epochs below are exactly as suggested in coco.py. Could be changed as needed.\n","\n","**Stage 1** involves training the network head.  \n","**Stage 2** fine-tunes layers from ResNet stage 4 and up.  \n","**Stage 3** fine-tunes the entire network."]},{"metadata":{"id":"-Edcmb52wr14","colab_type":"code","colab":{}},"cell_type":"code","source":["import imgaug\n","augmentation = imgaug.augmenters.Fliplr(0.5)\n","\n"," # Training - Stage 1\n","print(\"Training network heads\")\n","model.train(dataset_train, dataset_val,\n","            learning_rate=config.LEARNING_RATE,\n","            epochs=40,\n","            layers='heads',\n","            augmentation=augmentation)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yE7TZDgPu8Y7","colab_type":"code","colab":{}},"cell_type":"code","source":["# Training - Stage 2\n","# Finetune layers from ResNet stage 4 and up\n","print(\"Fine tune Resnet stage 4 and up\")\n","model.train(dataset_train, dataset_val,\n","            learning_rate=config.LEARNING_RATE,\n","            epochs=120,\n","            layers='4+',\n","            augmentation=augmentation)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qtx6TzNntkFQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Training - Stage 3\n","# Fine tune all layers\n","print(\"Fine tune all layers\")\n","model.train(dataset_train, dataset_val,\n","            learning_rate=config.LEARNING_RATE / 10,\n","            epochs=160,\n","            layers='all',\n","            augmentation=augmentation)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"itdsMn3_1haF","colab_type":"text"},"cell_type":"markdown","source":["## 4. Saving the final model to Google Drive"]},{"metadata":{"id":"WdOGRNwQuadg","colab_type":"code","colab":{}},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TzU1CizIvuMf","colab_type":"code","colab":{}},"cell_type":"code","source":["def upload_file(file_path, target_file_name):\n","  \"\"\"\n","  Upload a local file to Google Drive.\n","  \n","  Inputs -\n","    file_path - str, the local path to the file to be saved.\n","    target_file_name - str, the name of the file under which\n","      to save in Google Drive.\n","      \n","  Returns -\n","    uploaded_file_id - str, the id of the uploaded file as\n","      assigned by Google Drive.\n","  \"\"\"\n","  uploaded = drive.CreateFile({'title': target_file_name})\n","  uploaded.SetContentFile(file_path)\n","  uploaded.Upload()\n","  uploaded_file_id = uploaded.get('id')\n","  print('Uploaded file with ID {}'.format(uploaded_file_id))\n","  return uploaded_file_id\n","\n","\n","def download_file(file_path, file_id):\n","  \"\"\"\n","  Downloads a file from Google Drive and save it locally.\n","  \n","  Inputs -\n","    file_path - str, the local path to which the downloaded\n","      file is to be saved.\n","    file_id - str, the id of the uploaded file as\n","      assigned by Google Drive.\n","  \"\"\"\n","  f_ = drive.CreateFile({'id': file_id})\n","  f_.GetContentFile(file_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wfjw03Saxa1L","colab_type":"code","colab":{}},"cell_type":"code","source":["target_file_name = 'elu_model.h5'  # Name in which to save the model\n","final_model_path = 'path/to/final/model'\n","upload_file(final_model_path, target_file_name)"],"execution_count":0,"outputs":[]}]}