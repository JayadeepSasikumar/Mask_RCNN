{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from davis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load up the `test_results_dict` downloaded from the Google Drive.\n",
    "\n",
    "If done in fragments, the dictionaries should be combined to form a single dictionary.  \n",
    "train_results_dict and val_results_dict can also be loaded (if predicted for)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "test_results_dict = {}\n",
    "with open('test_results_dict.pickle', 'rb') as fp:\n",
    "    test_results_dict = pickle.load(fp)\n",
    "    \n",
    "train_results_dict = {}\n",
    "with open('train_results_dict.pickle', 'rb') as fp:\n",
    "    train_results_dict = pickle.load(fp)\n",
    "    \n",
    "val_results_dict = {}\n",
    "with open('val_results_dict.pickle', 'rb') as fp:\n",
    "    val_results_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [dataset_train, dataset_val, dataset_test]\n",
    "results_dicts = [train_results_dict, val_results_dict, test_results_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The folder name to which each prediction is to be written is\n",
    "added on to the dataset. This could've been done when the\n",
    "images were actually loaded to the dataset (load_images).\n",
    "\"\"\"\n",
    "for dataset in datasets:\n",
    "    for image_id in dataset.image_ids:\n",
    "        image_path = dataset.image_info[image_id]['path']\n",
    "        dataset.image_info[image_id]['folder_name'] = image_path.split('/')[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write the segmentations and masks to local folders.\n",
    "\n",
    "The target root folders should be given to `write_segmentations()` and `write_transformed_masks()` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_info = {}\n",
    "\n",
    "def get_mask(i, image_id):\n",
    "    \"\"\"\n",
    "    Given a dataset number and an image_id, returns the\n",
    "    predicted mask reshaped to 832, 832, 3.\n",
    "    \n",
    "    Inputs -\n",
    "        i - dataset number:\n",
    "            0 - train\n",
    "            1 - val\n",
    "            2 - test\n",
    "        image_id - the image_id for which the mask is to\n",
    "            be fetched.\n",
    "    \n",
    "    Working - Currently, only the most certain mask is\n",
    "        chosen and reshaped. This need not be the best\n",
    "        way to proceed.\n",
    "        \n",
    "    A possible solution - Consider all the different\n",
    "        predicted masks to form the final mask. A\n",
    "        threshold should be set, each mask has to\n",
    "        have a p% overlap with the actual image to\n",
    "        be considered for the final mask.\n",
    "        \n",
    "    Returns -\n",
    "        mask - a np.ndarray of shape (832, 832, 3),\n",
    "            the final predicted mask for the image.\n",
    "\n",
    "    \"\"\"\n",
    "    image_masks = results_dicts[i][image_id]['masks']\n",
    "    if image_masks.shape == (832, 832, 0):\n",
    "        mask = np.zeros((832, 832, 3))\n",
    "    else:\n",
    "        mask = image_masks[:, :, 0:1]\n",
    "        broadcaster = np.ones((1, 3))\n",
    "        mask = mask * broadcaster\n",
    "    return mask\n",
    "\n",
    "def write_mask(mask, mask_path):\n",
    "    \"\"\"\n",
    "    Takes the mask and the path to which it should be\n",
    "    written and writes it.\n",
    "    \n",
    "    Inputs -\n",
    "        mask - a np.ndarray of shape (832, 832, 3),\n",
    "            the final predicted mask for the image.\n",
    "        mask_path - a local location to which the\n",
    "            mask image should be written.\n",
    "    \n",
    "    Working -\n",
    "        The mask should be multiplied by 255 to bring\n",
    "        the values back to scale, otherwise a near-black\n",
    "        image would be saved.\n",
    "    \"\"\"\n",
    "    mask = mask * 255\n",
    "    mask = mask.astype('uint8')\n",
    "    cv2.imwrite(mask_path, mask)\n",
    "\n",
    "def write_segmentations(segmentations_path='segmentations'):\n",
    "    \"\"\"\n",
    "    Write the segmentations in the proper folder structure.\n",
    "    \"\"\"\n",
    "    def _add_to_sequence_info(sequence_name, image_id, dataset):\n",
    "        if sequence_name not in sequence_info:\n",
    "            sequence_info[sequence_name] = {\n",
    "                'image_ids': [],\n",
    "                'dataset': dataset,\n",
    "            }\n",
    "        sequence_info[sequence_name]['image_ids'].append(image_id)\n",
    "        \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        for image_id in dataset.image_ids:\n",
    "            image_info = dataset.image_info[image_id]\n",
    "            folder_path = os.path.join(segmentations_path,\n",
    "                                        image_info['folder_name'])\n",
    "            _add_to_sequence_info(image_info['folder_name'], image_id, dataset)\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            mask_path = os.path.join(folder_path,\n",
    "                                     image_info['pic_name'])\n",
    "            mask = get_mask(i, image_id)\n",
    "            dataset.image_info[image_id]['segmentation_path'] = mask_path\n",
    "            write_mask(mask, mask_path)\n",
    "\n",
    "def write_transformed_masks(masks_path, scale, padding, crop):\n",
    "    \"\"\"\n",
    "    Transforming the original masks for evaluation\n",
    "    \"\"\"\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        for image_id in dataset.image_ids:\n",
    "            image_info = dataset.image_info[image_id]\n",
    "            original_mask = dataset.load_mask(image_id=image_id)[0]\n",
    "            transformed_mask = utils.resize_mask(original_mask,\n",
    "                                                 scale, padding, crop)\n",
    "            folder_path = os.path.join(masks_path,\n",
    "                                       image_info['folder_name'])\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            mask_path = os.path.join(folder_path,\n",
    "                                     image_info['pic_name'])\n",
    "            dataset.image_info[image_id]['transformed_mask_path'] = mask_path\n",
    "            write_mask(transformed_mask, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Need to get the scale, padding and crop used to resize\n",
    "the image. The original image was 854X480. This needed to\n",
    "be resized into an image of equal height and width and the\n",
    "dimension should have been divisible by 2 at least 6 times.\n",
    "832X832 was chosen as it was the nearest number to 854 that\n",
    "satisfies this criterion.\n",
    "\n",
    "This same transformation needs to be applied to the ground\n",
    "truth masks as well in order to be consistent.\n",
    "\"\"\"\n",
    "image = dataset_test.load_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, window, scale, padding, crop = utils.resize_image(\n",
    "    image,\n",
    "    min_dim=config.IMAGE_MIN_DIM,\n",
    "    min_scale=config.IMAGE_MIN_SCALE,\n",
    "    max_dim=config.IMAGE_MAX_DIM,\n",
    "    mode=config.IMAGE_RESIZE_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Writing the segmentations and transformed ground truth masks\n",
    "in the proper folder structure as required. Need not be run\n",
    "multiple times.\n",
    "\n",
    "TODO: Alter the functions called here to skip writing the\n",
    "files if the directory is found in the specified location, so\n",
    "that no time is wasted even if these functions are called\n",
    "multiple times.\n",
    "\"\"\"\n",
    "write_segmentations('segmentations')\n",
    "write_transformed_masks('transformed_masks', scale, padding, crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods for computing IoU and mean IoU - Computing mean IoUs over various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(prediction, actual):\n",
    "    \"\"\"\n",
    "    Given the prediction and the ground truth, computes\n",
    "    and returns the Jaccard index (Intersection Over Union)\n",
    "    for the pair.\n",
    "    \n",
    "    The sizes of the intersection and the union are also\n",
    "    returned to facilitate the aggregation over directories.\n",
    "    \n",
    "    Inputs -\n",
    "        prediction - an np.ndarray with the predicted mask.\n",
    "        actual - an np.ndarray with the ground truth mask.\n",
    "    \n",
    "    Assumptions - \n",
    "        1. There is only a single mask of white colour\n",
    "            on a black background.\n",
    "        2. The prediction and the actual are of same shape,\n",
    "            right now (832, 832, 3).\n",
    "    \n",
    "    Working -\n",
    "        1. Reshape the masks to 1 channel only, this is\n",
    "            because all the channels would be same.\n",
    "        2. Get sum of prediction & actual (intersection).\n",
    "        3. Get sum of prediction | actual (union).\n",
    "        4. Divide intersection by union.\n",
    "        \n",
    "    Returns -\n",
    "        iou - a np.float64, the Intersection Over Union value\n",
    "            for the pair of images.\n",
    "        intersection_size - the count of pixels in intersection.\n",
    "        union_size - the count of pixels in union.\n",
    "    \"\"\"\n",
    "    prediction = prediction[:, :, 0:1]\n",
    "    actual = actual[:, :, 0:1]\n",
    "    intersection = prediction & actual\n",
    "    union = prediction | actual\n",
    "    intersection_size = intersection.sum()\n",
    "    union_size = union.sum()\n",
    "    iou = intersection_size / union_size\n",
    "    return iou, intersection_size, union_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_iou(prediction_paths, actual_paths):\n",
    "    \"\"\"\n",
    "    Given a directory of predictions and another of the\n",
    "    respective ground truths, computes the mean IOUs over\n",
    "    all the pair of images inside it.\n",
    "    \n",
    "    Inputs -\n",
    "        prediction_paths - list of str, each item in the list\n",
    "            a path to a predicted segmentation.\n",
    "        actual_paths - list of str, each item in the list a\n",
    "            path to a ground truth.\n",
    "    \n",
    "    Assumptions -\n",
    "        1. The order should is maintained. ith item in\n",
    "            prediction_paths is the segmentation of ith item\n",
    "            in actual_paths.\n",
    "            \n",
    "    Working -\n",
    "        1. Iterate through the lists, and keep calling\n",
    "            get_iou() for each pair of items.\n",
    "        2. Keep adding intersection_size and union_size\n",
    "            returned by get_iou() in two variables,\n",
    "            total_i and total_u respectively.\n",
    "        3. mean_iou = total_i / total_u\n",
    "    \n",
    "    Returns -\n",
    "        mean_iou - the mean Intersection Over Union over the\n",
    "            given predictions and ground truths.\n",
    "    \"\"\"\n",
    "    total_i = 0\n",
    "    total_u = 0\n",
    "    for i in range(len(prediction_paths)):\n",
    "        prediction = cv2.imread(prediction_paths[i])\n",
    "        actual = cv2.imread(actual_paths[i])\n",
    "        iou, intersection_size, union_size = get_iou(prediction, actual)\n",
    "        total_i += intersection_size\n",
    "        total_u += union_size\n",
    "    mean_iou = total_i / total_u\n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the mean IOU over training data\n",
    "prediction_paths = [item['segmentation_path'] for item in dataset_train.image_info]\n",
    "actual_paths = [item['transformed_mask_path'] for item in dataset_train.image_info]\n",
    "mean_training_iou = get_mean_iou(prediction_paths, actual_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the mean IOU over validation data\n",
    "prediction_paths = [item['segmentation_path'] for item in dataset_val.image_info]\n",
    "actual_paths = [item['transformed_mask_path'] for item in dataset_val.image_info]\n",
    "mean_validation_iou = get_mean_iou(prediction_paths, actual_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the mean IOU over test data\n",
    "prediction_paths = [item['segmentation_path'] for item in dataset_test.image_info]\n",
    "actual_paths = [item['transformed_mask_path'] for item in dataset_test.image_info]\n",
    "# mean_testing_iou = get_mean_iou(prediction_paths, actual_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the mean IOU over entire data\n",
    "prediction_paths = []\n",
    "for dataset in datasets:\n",
    "    for item in dataset.image_info:\n",
    "        prediction_paths.append(item['segmentation_path'])\n",
    "actual_paths = []\n",
    "for dataset in datasets:\n",
    "    for item in dataset.image_info:\n",
    "        actual_paths.append(item['transformed_mask_path'])\n",
    "mean_overall_iou = get_mean_iou(prediction_paths, actual_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the mean IOU over each video sequence - \n",
    "from collections import defaultdict\n",
    "\n",
    "def get_sequence_wise_ious(datasets):\n",
    "    video_sequences = {}\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        for image_info in dataset.image_info:\n",
    "            sequence = image_info['folder_name']\n",
    "            if not image_info['folder_name'] in video_sequences:\n",
    "                video_sequences[sequence] = defaultdict(list)\n",
    "            video_sequences[sequence]['prediction_paths'].append(image_info['segmentation_path'])\n",
    "            video_sequences[sequence]['actual_paths'].append(image_info['transformed_mask_path'])\n",
    "\n",
    "    mean_ious = {}\n",
    "    for sequence, paths in video_sequences.items():\n",
    "        mean_ious[sequence] = get_mean_iou(paths['prediction_paths'], paths['actual_paths'])\n",
    "    return mean_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_ious = get_sequence_wise_ious(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getting mean IoU over different video sequence attributes.\n",
    "\n",
    "db_info.yml is provided along with the DAVIS dataset. This file provides information on the different attributes encountered in the different video sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_db_info():\n",
    "    with open(\"db_info.yml\", 'r') as stream:\n",
    "        db_info = yaml.load(stream)\n",
    "    return db_info\n",
    "\n",
    "db_info = get_db_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = set()\n",
    "val_sequences = set()\n",
    "test_sequences = set()\n",
    "sequences = [train_sequences, val_sequences, test_sequences]\n",
    "for ix, dataset in enumerate(datasets):\n",
    "    print (ix)\n",
    "    for image_id in dataset.image_ids:\n",
    "        sequences[ix].add(dataset.image_info[image_id]['folder_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_list = list(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_dataset_dict = {}\n",
    "for sequence in sequence_wise_ious.keys():\n",
    "    if sequence in train_sequences:\n",
    "        sequence_dataset_dict[sequence] = 'train'\n",
    "    elif sequence in val_sequences:\n",
    "        sequence_dataset_dict[sequence] = 'validation'\n",
    "    else:\n",
    "        sequence_dataset_dict[sequence] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ious = {sequence: iou for sequence, iou in sequence_wise_ious.items() if sequence in train_sequences}\n",
    "val_ious = {sequence: iou for sequence, iou in sequence_wise_ious.items() if sequence in val_sequences}\n",
    "test_ious = {sequence: iou for sequence, iou in sequence_wise_ious.items() if sequence in test_sequences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequences = []\n",
    "train_sequences = []\n",
    "for sequence in db_info['sequences']:\n",
    "    if sequence['set'] == 'test':\n",
    "        val_sequences.append(sequence)\n",
    "    else:\n",
    "        train_sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attributes_dict = {sequence['name']: sequence['attributes'] for sequence in train_sequences}\n",
    "val_attributes_dict = {sequence['name']: sequence['attributes'] for sequence in val_sequences}\n",
    "\n",
    "\n",
    "attributes = db_info['attributes']\n",
    "train_attribute_sequences_dict = defaultdict(list)\n",
    "val_attribute_sequences_dict = defaultdict(list)\n",
    "for key, value in train_attributes_dict.items():\n",
    "    for attribute in value:\n",
    "        train_attribute_sequences_dict[attribute].append(key)\n",
    "for key, value in val_attributes_dict.items():\n",
    "    for attribute in value:\n",
    "        val_attribute_sequences_dict[attribute].append(key)\n",
    "\n",
    "train_attributes = {key: len(value) for key, value in train_attribute_sequences_dict.items()}\n",
    "val_attributes = {key: len(value) for key, value in val_attribute_sequences_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_attributes_dict = {sequence['name']: sequence['attributes'] for sequence in db_info['sequences'] if\n",
    "                                  sequence['name'] in train_sequences}\n",
    "final_val_attributes_dict = {sequence['name']: sequence['attributes'] for sequence in db_info['sequences'] if\n",
    "                                  sequence['name'] in val_sequences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes_count(attributes):\n",
    "    attributes_count = {}\n",
    "    for attributes_list in attributes:\n",
    "        for attribute in attributes_list:\n",
    "            attributes_count[attribute] = attributes_count.get(attribute, 0) + 1\n",
    "    return attributes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attributes = get_attributes_count(final_train_attributes_dict.values())\n",
    "val_attributes = get_attributes_count(final_val_attributes_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folders = ['soapbox', 'scooter-black', 'parkour', 'paragliding-launch', 'motocross-jump']\n",
    "test_attributes_dict = {name: attributes for name, attributes in val_attributes_dict.items() if name in test_folders}\n",
    "split_val_attributes_dict = {name: attributes for name, attributes in val_attributes_dict.items() if name not in test_folders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attribute_sequences_dict = defaultdict(list)\n",
    "split_val_attribute_sequences_dict = defaultdict(list)\n",
    "for key, value in test_attributes_dict.items():\n",
    "    for attribute in value:\n",
    "        test_attribute_sequences_dict[attribute].append(key)\n",
    "test_attributes = {key: len(value) for key, value in test_attribute_sequences_dict.items()}\n",
    "for key, value in split_val_attributes_dict.items():\n",
    "    for attribute in value:\n",
    "        split_val_attribute_sequences_dict[attribute].append(key)\n",
    "split_val_attributes = {key: len(value) for key, value in split_val_attribute_sequences_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_attributes_dict = {sequence['name']: sequence['attributes'] for sequence in db_info['sequences']}\n",
    "attributes = db_info['attributes']\n",
    "attribute_sequences_dict = defaultdict(list)\n",
    "for key, value in sequence_attributes_dict.items():\n",
    "    for attribute in value:\n",
    "        attribute_sequences_dict[attribute].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(sequence_names, sequence_info):\n",
    "    \"\"\"\n",
    "    Takes in a list of sequence names and returns the segmentation\n",
    "    paths and the transformed mask paths for all the frames under\n",
    "    those sequences\n",
    "    \n",
    "    Input -\n",
    "        sequence_names - list of str, names of video sequences.\n",
    "        sequence_info - (global) dict, having sequence_names as\n",
    "            keys and respective frame information as values.\n",
    "    Returns -\n",
    "        prediction_paths, actual_paths - lists of str, paths\n",
    "            containing all the predictions for these sequences\n",
    "            and the ground truths for these sequences.\n",
    "    \"\"\"\n",
    "    prediction_paths = []\n",
    "    actual_paths = []\n",
    "    for sequence in sequence_names:\n",
    "        dataset = sequence_info[sequence]['dataset']\n",
    "        for image_id in sequence_info[sequence]['image_ids']:\n",
    "            prediction_paths.append(dataset.image_info[image_id]['segmentation_path'])\n",
    "            actual_paths.append(dataset.image_info[image_id]['transformed_mask_path'])\n",
    "    return prediction_paths, actual_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_wise_mean_ious = {}\n",
    "for attribute in attributes:\n",
    "    prediction_paths, actual_paths = get_paths(attribute_sequences_dict[attribute], sequence_info)\n",
    "    attribute_wise_mean_ious[attribute] = get_mean_iou(prediction_paths, actual_paths)\n",
    "sorted(attribute_wise_mean_ious, key=lambda x: attribute_wise_mean_ious[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = {}\n",
    "for key, value in attributes_dict.items():\n",
    "    sequences[key] = {}\n",
    "    sequences[key]['attributes'] = value\n",
    "for key, value in mean_ious.items():\n",
    "    sequences[key]['mean_iou'] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Appendix - visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "class InferenceConfig(DAVISConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8\n",
    "\n",
    "inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking on a random image from test dataset\n",
    "image_id = 1300\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_test, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_results_dict[image_id]\n",
    "r = results\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_train.class_names, r['scores'], ax=get_ax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask_rcnn",
   "language": "python",
   "name": "mask_rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
