{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"davis_mask_rcnn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"nHqKUAPG272I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"4ef13748-32a8-4cbd-9f50-a5e13655c86e","executionInfo":{"status":"ok","timestamp":1548267885543,"user_tz":0,"elapsed":10876,"user":{"displayName":"Jayadeep Sasikumar","photoUrl":"","userId":"11146727263730048505"}}},"cell_type":"code","source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","\n","\n","def restart_kernel():\n","  \"\"\"\n","  Restart the kernel. This will clear off the variables as\n","  well as the entire workspace. Any downloaded files or cloned repos\n","  will be cleared off. Think of this as a hard reset.\n","  \"\"\"\n","  os.system('kill -9 -1')\n","  \n","def check_available_memory():\n","  \"\"\"\n","  Prints a summary of both the general and GPU RAM status.\n","  \"\"\"\n","  GPUs = GPU.getGPUs()\n","  # XXX: only one GPU on Colab and isnâ€™t guaranteed\n","  gpu = GPUs[0]\n","  def printm():\n","   process = psutil.Process(os.getpid())\n","   print(\"Gen RAM Free: \" + \\\n","         humanize.naturalsize( psutil.virtual_memory().available ),\n","         \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","   print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | \"\\\n","         \"Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed,\n","                                  gpu.memoryUtil*100, gpu.memoryTotal))\n","  printm()\n","  \n","def refresh_repo():\n","  \"\"\"\n","  Refreshes the local repo. If the repo is not present, clones the Mask R-CNN\n","  fork, if it's present, takes a pull from the origin.\n","  \"\"\"\n","  items = os.listdir()\n","  if items == ['.config', 'sample_data']:\n","    os.system('git clone https://github.com/JayadeepSasikumar/Mask_RCNN.git')\n","  else:\n","    if items == ['.config', 'Mask_RCNN', 'sample_data']:\n","      os.system('cd Mask_RCNN')\n","    os.system('git pull origin master')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"],"name":"stdout"}]},{"metadata":{"id":"evpGHM2l3Kcz","colab_type":"text"},"cell_type":"markdown","source":["## Cloning into (or taking a pull of) the Mask R-CNN fork"]},{"metadata":{"id":"3DTw8wHg3QMF","colab_type":"code","colab":{}},"cell_type":"code","source":["refresh_repo()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AkogYf4m3Ual","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9fea3828-9781-41d6-baee-a75fc8373979","executionInfo":{"status":"ok","timestamp":1548267937869,"user_tz":0,"elapsed":22896,"user":{"displayName":"Jayadeep Sasikumar","photoUrl":"","userId":"11146727263730048505"}}},"cell_type":"code","source":["cd /content/Mask_RCNN/samples/davis"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/Mask_RCNN/samples/davis\n"],"name":"stdout"}]},{"metadata":{"id":"nU2wLvmT4JUO","colab_type":"code","colab":{}},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def upload_file(file_path, target_file_name):\n","  \"\"\"\n","  Upload a local file to Google Drive.\n","  \n","  Inputs -\n","    file_path - str, the local path to the file to be saved.\n","    target_file_name - str, the name of the file under which\n","      to save in Google Drive.\n","      \n","  Returns -\n","    uploaded_file_id - str, the id of the uploaded file as\n","      assigned by Google Drive.\n","  \"\"\"\n","  uploaded = drive.CreateFile({'title': target_file_name})\n","  uploaded.SetContentFile(file_path)\n","  uploaded.Upload()\n","  uploaded_file_id = uploaded.get('id')\n","  print('Uploaded file with ID {}'.format(uploaded_file_id))\n","  return uploaded_file_id\n","\n","\n","def download_file(file_path, file_id):\n","  \"\"\"\n","  Downloads a file from Google Drive and save it locally.\n","  \n","  Inputs -\n","    file_path - str, the local path to which the downloaded\n","      file is to be saved.\n","    file_id - str, the id of the uploaded file as\n","      assigned by Google Drive.\n","  \"\"\"\n","  f_ = drive.CreateFile({'id': file_id})\n","  f_.GetContentFile(file_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RFrJdQSi-MkN","colab_type":"text"},"cell_type":"markdown","source":["# Part 1 - Training the model\n","\n","## 1. Loading the required imports and setting the constants"]},{"metadata":{"id":"4-LIi12i3a5I","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import cv2\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"../../\")\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn.config import Config\n","from mrcnn import utils\n","import mrcnn.elu_model\n","import mrcnn.model\n","\n","from mrcnn import visualize\n","from mrcnn.model import log\n","\n","%matplotlib inline \n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","DATA_DIR = os.path.join(ROOT_DIR, \"davis_data\")\n","\n","# relu or elu, modellib would be changed based on this setting\n","ACTIVATION_UNIT = 'elu'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wZAV4D_g5adK","colab_type":"text"},"cell_type":"markdown","source":["## 2. Choosing the proper model file according to the ACTIVATION_UNIT setting"]},{"metadata":{"id":"CosSTzN7OTyq","colab_type":"code","colab":{}},"cell_type":"code","source":["if ACTIVATION_UNIT == 'relu':\n","  modellib = mrcnn.model\n","  # Local path to trained weights file\n","  COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n","  # Download COCO trained weights from Releases if needed\n","  if not os.path.exists(COCO_MODEL_PATH):\n","      utils.download_trained_weights(COCO_MODEL_PATH)\n","else:\n","  modellib = mrcnn.elu_model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VPvpqWT75hT1","colab_type":"text"},"cell_type":"markdown","source":["## 3. Overriding the default configurations for the DAVIS 2016 dataset."]},{"metadata":{"id":"cvf7Re4A3eD9","colab_type":"code","colab":{}},"cell_type":"code","source":["class DAVISConfig(Config):\n","    \"\"\"Configuration for training on the DAVIS 2016 dataset.\n","    Derives from the base Config class and overrides values specific\n","    to the DAVIS 2016 dataset.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"davis\"\n","\n","    # Batch size is 1 (GPU_COUNT * IMAGES_PER_GPU).\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1  # because of the limited memory\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # background + object\n","\n","    # Use small images for faster training. Set the limits of the small side\n","    # the large side, and that determines the image shape.\n","    IMAGE_MIN_DIM = 832\n","    IMAGE_MAX_DIM = 832\n","    IMAGE_RESIZE_MODE = \"square\"  # This is the default option as well\n","\n","    # Use smaller anchors because our image and objects are small\n","    RPN_ANCHOR_SCALES = (32, 64, 128, 256)  # anchor side in pixels\n","\n","    # Reduce training ROIs per image because the images are small and have\n","    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n","    TRAIN_ROIS_PER_IMAGE = 5  #32\n","\n","    # Need not be the same size as the training dataset\n","    STEPS_PER_EPOCH = 500\n","\n","    # Use larger numbers for higher confidence, smaller ones for faster\n","    # epochs.\n","    VALIDATION_STEPS = 356\n","    \n","config = DAVISConfig()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-g5DMAqk56eB","colab_type":"text"},"cell_type":"markdown","source":["## 4. Extending the Dataset class to serve the DAVIS 2016 dataset.\n","\n","Three methods need to be implemented for any custom dataset to work with Mask R-CNN -  \n","1. image_reference  \n","2. load_images . \n","3. load_mask"]},{"metadata":{"id":"k-Eddzcd3qDK","colab_type":"code","colab":{}},"cell_type":"code","source":["class DAVISDataset(utils.Dataset):\n","    \"\"\"Encapsulates the DAVIS dataset.\n","    \"\"\"\n","    def image_reference(self, image_id):\n","        \"\"\"Return the davis data of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"davis\":\n","            return info[\"davis\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)\n","    \n","    def load_images(self, mode='train'):\n","        \"\"\"\n","        Loads the 480p images from the DAVIS dataset.\n","        \"\"\"\n","        images_dir = os.path.join(DATA_DIR, 'JPEGImages', '480p')\n","        self.add_class('davis', 1, 'object')\n","        image_paths_file_name = mode + '.txt'\n","        image_paths_file_path = os.path.join(DATA_DIR, image_paths_file_name)\n","        with open(image_paths_file_path, 'r') as image_paths_file:\n","            for i, line in enumerate(image_paths_file):\n","                try:\n","                  image_path, mask_path = line.split()[0], line.split()[1]\n","                except IndexError:\n","                  continue\n","                image_path = DATA_DIR + image_path\n","                mask_path = DATA_DIR + mask_path\n","                pic_name = image_path.split('/')[-1]\n","                pic_class = image_path.split('/')[-2]\n","                self.add_image(\"davis\", image_id=i, path=image_path,\n","                           pic_name=pic_name, pic_class='object',\n","                           mask_path=mask_path)\n","            \n","    def load_mask(self, image_id):\n","        \"\"\"Load instance masks for the given image.\n","\n","        Different datasets use different ways to store masks. Override this\n","        method to load instance masks and return them in the form of am\n","        array of binary masks of shape [height, width, instances].\n","\n","        Returns:\n","            masks: A bool array of shape [height, width, instance count] with\n","                a binary mask per instance.\n","            class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        info = self.image_info[image_id]\n","        mask_path = info['mask_path']\n","        pic_class = info['pic_class']\n","        mask = cv2.imread(mask_path)\n","        mask = mask[:, :, 0:1]\n","        class_ids = np.array([self.class_names.index(pic_class)])\n","        return mask.astype(np.bool), class_ids.astype(np.int32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tLoaRcJa6S9Z","colab_type":"text"},"cell_type":"markdown","source":["## 5. Creating the training, validation and test datasets and preparing them."]},{"metadata":{"id":"Vnlt5hDl36Hw","colab_type":"code","colab":{}},"cell_type":"code","source":["# Training dataset\n","dataset_train = DAVISDataset()\n","dataset_train.load_images(mode='train')\n","dataset_train.prepare()\n","\n","# Validation dataset\n","dataset_val = DAVISDataset()\n","dataset_val.load_images(mode='val')\n","dataset_val.prepare()\n","\n","# Test dataset\n","dataset_test = DAVISDataset()\n","dataset_test.load_images(mode='test')\n","dataset_test.prepare()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_k3o0Lil6dH5","colab_type":"text"},"cell_type":"markdown","source":["## 6. Create a model and load the pre-trained weights for the backbone."]},{"metadata":{"id":"0IiEHOGd38uC","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create model in training mode\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                          model_dir=MODEL_DIR)\n","\n","if ACTIVATION_UNIT == 'elu':\n","  model_google_drive_id = 'google_drive_id_of_the_elu_model'\n","  model_path = 'path/where/to/save/model'\n","  download_file(model_path, model_google_drive_id)\n","  model.load_weights(model_path, by_name=True,\n","                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n","                            \"mrcnn_bbox\", \"mrcnn_mask\"])\n","else:\n","  model.load_weights(COCO_MODEL_PATH, by_name=True,\n","                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n","                                \"mrcnn_bbox\", \"mrcnn_mask\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cejZRASo7rh2","colab_type":"text"},"cell_type":"markdown","source":["## 7. Training the model on the DAVIS 2016 dataset\n","\n","Training is done in 2 stages, the number of epochs below are exactly as suggested in coco.py. Could be changed as needed.\n","\n","**Stage 1** involves training the network head.  \n","**Stage 2** fine-tunes the entire network.  \n","  \n","After each epoch, the trained model is saved at MODEL_DIR. At the end of each training phase, the model at the end of the epoch at which the validation error elbows out could be chosen as the model to go ahead with."]},{"metadata":{"colab_type":"code","id":"6C8bqOmt7kRD","colab":{}},"cell_type":"code","source":["# Stage 1 - training the head\n","model.train(dataset_train, dataset_val, \n","            learning_rate=config.LEARNING_RATE,\n","            epochs = 10,\n","            layers='heads')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JlttKvVr7gVd","colab_type":"code","colab":{}},"cell_type":"code","source":["# Choose the model from the proper epoch as stated above.\n","best_model_path = 'path/to/the/best/model'\n","\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                          model_dir=MODEL_DIR)\n","model.load_weights(best_model_path, by_name=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-qSkE-M8LcDu","colab_type":"code","colab":{}},"cell_type":"code","source":["# Stage 2 - training the entire model\n","best_model.train(dataset_train, dataset_val, \n","                 learning_rate=config.LEARNING_RATE / 3,\n","                 epochs=10, \n","                 layers=\"all\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Too-IENT8vbu","colab_type":"code","colab":{}},"cell_type":"code","source":["# Choose the model with the least validation loss in the second training phase\n","trained_model_path = 'path/to/model/with/least/validation/loss'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"daXtbsSd8woA","colab_type":"text"},"cell_type":"markdown","source":["## 8. Create a base model for inference\n","\n","1. Create a new config for inference.  \n","2. Create a new model in inference mode and load it up with the weights of the model chosen as the best one after the second phase of training.\n","3. This model would act as the base model on which one-shot fine-tuning will be applied."]},{"metadata":{"id":"2PmzTu4ELngT","colab_type":"code","colab":{}},"cell_type":"code","source":["class InferenceConfig(DAVISConfig):\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    DETECTION_MIN_CONFIDENCE = 0.8\n","\n","inference_config = InferenceConfig()\n","\n","\n","# Recreate the model in inference mode\n","trained_model = modellib.MaskRCNN(mode=\"inference\", \n","                              config=inference_config,\n","                              model_dir=MODEL_DIR)\n","trained_model.load_weights(trained_model_path, by_name=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ao9a5dhh9ev_","colab_type":"text"},"cell_type":"markdown","source":["# Part 2 - One-shot fine-tuning\n","\n","## 9. Create a new Config\n","\n","1. An epoch would contain only one image - the idea is to fine-tune the entire model with the first frame of a video sequence, and its ground-truth."]},{"metadata":{"id":"0OHgyUziL6Ya","colab_type":"code","colab":{}},"cell_type":"code","source":["# def get_specific_model(image_id, dataset.)\n","sequence_name = \"\"\n","class SpecificConfig(Config):\n","    \"\"\"Configuration for training on the DAVIS 2017 dataset.\n","    Derives from the base Config class and overrides values specific\n","    to the DAVIS 2017 dataset. - SEQUENCE SPECIFIC VERSION\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"specific\"\n","\n","    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n","    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # background + object\n","\n","    # Use small images for faster training. Set the limits of the small side\n","    # the large side, and that determines the image shape.\n","    IMAGE_MIN_DIM = 832\n","    IMAGE_MAX_DIM = 832\n","    IMAGE_RESIZE_MODE = \"square\"  # This is the default option as well\n","\n","    # Use smaller anchors because our image and objects are small\n","    RPN_ANCHOR_SCALES = (32, 64, 128, 256)  # anchor side in pixels\n","\n","    # Reduce training ROIs per image because the images are small and have\n","    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n","    TRAIN_ROIS_PER_IMAGE = 5  #32\n","\n","    # Use a small epoch since the data is simple\n","    STEPS_PER_EPOCH = 1\n","\n","    # use small validation steps since the epoch is small\n","    VALIDATION_STEPS = 1\n","    \n","sp_config = SpecificConfig()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hCP4KXPU-IUK","colab_type":"text"},"cell_type":"markdown","source":["## 10. Extending the Dataset class to serve a single video sequence from DAVIS 2016 dataset.\n","\n","1. A global variable `sequence_name` is maintained which will be used to maintain which of the test sequences are being predicted for at any moment during execution.  \n","2. When the mode is 'training', only the first frame from the video sequence will be returned as the training dataset.  \n","3. When the mode is 'test', all the frames for the sequence are returned.  \n"]},{"metadata":{"id":"M7aXPDkUMQUf","colab_type":"code","colab":{}},"cell_type":"code","source":["sequence_name = ''\n","\n","class SpecificDataset(utils.Dataset):\n","    \"\"\"Encapsulates the DAVIS dataset - returns a dataset with only one entry.\n","    \"\"\"\n","    def image_reference(self, image_id):\n","        \"\"\"Return the davis data of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"davis\":\n","            return info[\"davis\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)\n","    \n","    def load_images(self, mode='train'):\n","        \"\"\"\n","        Loads the 480p images from the DAVIS dataset.\n","        \"\"\"\n","        images_dir = os.path.join(DATA_DIR, 'JPEGImages', '480p')\n","        self.add_class('davis', 1, 'object')\n","        image_paths_file_name = 'test.txt'\n","        image_paths_file_path = os.path.join(DATA_DIR, image_paths_file_name)\n","        with open(image_paths_file_path, 'r') as image_paths_file:\n","            for i, line in enumerate(image_paths_file):\n","                try:\n","                  image_path, mask_path = line.split()[0], line.split()[1]\n","                except IndexError:\n","                  continue\n","                if mode == 'train':\n","                  if '00000' in image_path and sequence_name in image_path:\n","                    image_path = DATA_DIR + image_path\n","                    mask_path = DATA_DIR + mask_path\n","                    pic_name = image_path.split('/')[-1]\n","                    pic_class = image_path.split('/')[-2]\n","                    self.add_image(\"davis\", image_id=i, path=image_path,\n","                               pic_name=pic_name, pic_class='object',\n","                               mask_path=mask_path)\n","                elif mode == 'test':\n","                    if sequence_name in image_path and '00000' not in image_path:\n","                      image_path = DATA_DIR + image_path\n","                      mask_path = DATA_DIR + mask_path\n","                      pic_name = image_path.split('/')[-1]\n","                      pic_class = image_path.split('/')[-2]\n","                      self.add_image(\"davis\", image_id=i, path=image_path,\n","                                 pic_name=pic_name, pic_class='object',\n","                                 mask_path=mask_path) \n","                else:\n","                  if '00001' in image_path and sequence_name in image_path:\n","                    image_path = DATA_DIR + image_path\n","                    mask_path = DATA_DIR + mask_path\n","                    pic_name = image_path.split('/')[-1]\n","                    pic_class = image_path.split('/')[-2]\n","                    self.add_image(\"davis\", image_id=i, path=image_path,\n","                               pic_name=pic_name, pic_class='object',\n","                               mask_path=mask_path)\n","            \n","    def load_mask(self, image_id):\n","        \"\"\"Load instance masks for the given image.\n","\n","        Different datasets use different ways to store masks. Override this\n","        method to load instance masks and return them in the form of am\n","        array of binary masks of shape [height, width, instances].\n","\n","        Returns:\n","            masks: A bool array of shape [height, width, instance count] with\n","                a binary mask per instance.\n","            class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        info = self.image_info[image_id]\n","        mask_path = info['mask_path']\n","        pic_class = info['pic_class']\n","        mask = cv2.imread(mask_path)\n","        mask = mask[:, :, 0:1]\n","        class_ids = np.array([self.class_names.index(pic_class)])\n","        return mask.astype(np.bool), class_ids.astype(np.int32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H57MUHSMMRql","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_sp_datasets():\n","  \"\"\"\n","  Creates the training, validation and test datasets based\n","  on the video sequence that is currently being tested for\n","  and prepares them. The sequence being predicted for is\n","  understood by the SpecificDataset class from the global\n","  variable maintained, sequence_name.\n","  \"\"\"\n","  # Training dataset\n","  sp_dataset_train = SpecificDataset()\n","  sp_dataset_train.load_images(mode='train')\n","  sp_dataset_train.prepare()\n","\n","  # Validation dataset\n","  sp_dataset_val = SpecificDataset()\n","  sp_dataset_val.load_images(mode='val')\n","  sp_dataset_val.prepare()\n","\n","  # Test dataset\n","  sp_dataset_test = SpecificDataset()\n","  sp_dataset_test.load_images(mode='test')\n","  sp_dataset_test.prepare()\n","  \n","  return sp_dataset_train, sp_dataset_val"],"execution_count":0,"outputs":[]},{"metadata":{"id":"86_-ka7FMUe6","colab_type":"code","colab":{}},"cell_type":"code","source":["import glob\n","import os\n","\n","def get_specific_model():\n","  \"\"\"\n","  Returns the model fine-tuned on the first frame of the\n","  current sequence being predicted for.\n","  \n","  Returns -\n","    sp_inf_model - a Mask R-CNN model fine-tuned on the\n","      first frame of the current sequence being predicted\n","      for.\n","  \"\"\"\n","  specific_model = copy(trained_model)\n","  sp_dataset_train, sp_dataset_val = get_sp_datasets()\n","  specific_model.train(sp_dataset_train, sp_dataset_val, \n","                      learning_rate=config.LEARNING_RATE / 3,\n","                      epochs=1, \n","                      layers=\"all\")\n","  model_paths = glob.glob('/content/Mask_RCNN/logs/*/*')\n","  latest_model_path = max(model_paths, key=os.path.getctime)\n","  print (latest_model_path)\n","  sp_inf_model = modellib.MaskRCNN(mode=\"inference\", \n","                              config=inference_config,\n","                              model_dir=MODEL_DIR)\n","  sp_inf_model.load_weights(latest_model_path, by_name=True)\n","  return sp_inf_model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F9O1zZOHA3bc","colab_type":"text"},"cell_type":"markdown","source":["## 11. Use fine-tuned models for prediction\n","\n","1. Iterate through the test frames, and get the fine-tuned model for the specific sequence.  \n","2. Predict for the frame using the respective model.  \n","3. Store the results in `test_results_dict`. This would be used for evaluation.  \n","  \n","PS - the RAM constraints could cause problems with storing up all the different models. If faced with such a problem, the prediction could be done in batches, the `test_results_dict` for each batch pickled and uploaded to Google Drive. These pickled dicts can be later combined during evaluation."]},{"metadata":{"id":"jGW6p3AyMZVX","colab_type":"code","colab":{}},"cell_type":"code","source":["from copy import copy\n","test_sequence_names = ['car-roundabout', 'soapbox', 'goat', 'blackswan',\n","                       'cows', 'kite-surf', 'dance-twirl', 'breakdance',\n","                       'horsejump-high', 'paragliding-launch',\n","                       'scooter-black', 'camel', 'libby', 'parkour',\n","                       'drift-straight', 'drift-chicane', 'motocross-jump',\n","                       'dog', 'car-shadow', 'bmx-trees']\n","\n","sequence_name = \"\"\n","test_results_dict = {}\n","\n","\n","# dataset_train and dataset_val can also be predicted for the same way and\n","# saved and pickled and uploaded to Google Drive if needed.\n","for image_id in dataset_test.image_ids:\n","    # Load image and ground truth data\n","    mask_path = dataset_test.image_info[image_id]['mask_path']\n","    folder_name = mask_path.split('/')[-2]\n","    if sequence_name != folder_name:\n","      specific_model = get_specific_model()\n","      sequence_name = folder_name\n","    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n","        modellib.load_image_gt(dataset_test, inference_config,\n","                               image_id, use_mini_mask=False)\n","    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n","    # Run object detection\n","    results = specific_model.detect([image], verbose=0)\n","    test_results_dict[image_id] = results[0]\n","    print (\"\\r{}\".format(image_id), end=\"\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OXuJuvTzCWlp","colab_type":"text"},"cell_type":"markdown","source":["## 12. Pickle `test_results_dict` and upload it to Google Drive"]},{"metadata":{"id":"ayyEjb35NwS0","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","\n","test_results_path = 'path/to/save/test/results'\n","with open(test_results_path, 'wb') as fp:\n","  pickle.dump(test_results_dict, fp)\n","upload_file(test_results_path, 'test_results_dict.pickle')"],"execution_count":0,"outputs":[]}]}